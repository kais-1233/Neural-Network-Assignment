{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1b8009-9c8d-4195-906f-b8609ae2be6f",
   "metadata": {},
   "source": [
    "#### 1. What is deep learning, and how is it connected to artificial intelligence?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a612913-87a6-46bb-9e1d-9f25b86d0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning is a subset of machine learning in artificial intelligence that mimics the working of the human brain using neural networks with many layers. It allows machines to automatically learn features from raw data without manual feature extraction. It's used in speech recognition, image processing, NLP, and more. Deep learning is a core technique used to build intelligent systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326f52a-2e81-4698-881d-998b9f7f99ed",
   "metadata": {},
   "source": [
    "#### 2. What is a neural network, and what are the different types of neural networks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a206a3-170c-4bea-939c-299c1ff87687",
   "metadata": {},
   "outputs": [],
   "source": [
    " # A neural network is a computational model inspired by the human brain, consisting of layers of interconnected nodes (neurons). \n",
    "\n",
    " #  Types:\n",
    "\n",
    " #  Feedforward Neural Network (FNN)\n",
    "\n",
    " #  Convolutional Neural Network (CNN)\n",
    "\n",
    " #  Recurrent Neural Network (RNN)\n",
    "\n",
    " #  Generative Adversarial Network (GAN)\n",
    "\n",
    " #  Autoencoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd2404-1b71-477d-9259-dda8f8d8402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is the mathematical structure of a neural network?\n",
    "\n",
    "# A neural network processes inputs using layers of neurons. Each neuron performs:\n",
    "# z = w·x + b (weighted sum) followed by an activation a = f(z).\n",
    "# Training involves minimizing a loss function L(y, ŷ) using optimization (like gradient descent). Weight updates are done using derivatives from backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69f155-c3f4-4dc8-aa97-b9e13e534ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. What is an activation function, and why is it essential in neural networks\n",
    "\n",
    "\n",
    "# An activation function introduces non-linearity into the network, enabling it to learn complex relationships. Without it, the network would behave like a linear model regardless of its depth. It helps the network to capture patterns in data and make accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c409b-420e-4169-ab2b-9cb847474166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Could you list some common activation functions used in neural networks?\n",
    "\n",
    "# Yes, common activation functions include:\n",
    "\n",
    "# ReLU (Rectified Linear Unit): Efficient and widely used.\n",
    "\n",
    "# Sigmoid: Used in binary classification.\n",
    "\n",
    "# Tanh: Zero-centered and used in RNNs.\n",
    "\n",
    "# Leaky ReLU: Fixes dying ReLU problem.\n",
    "\n",
    "# Softmax: Used in multi-class classification output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1060b7-9cd8-4ddd-b5ef-6c2cc9b72115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. What is a multilayer neural network?\n",
    "\n",
    "# A multilayer neural network consists of an input layer, one or more hidden layers, and an output layer. Each layer contains multiple neurons, and the layers are fully or partially connected. These networks are capable of learning complex patterns by transforming inputs through layers of computation. They form the basis of deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff9323-244b-419e-9d16-46d829b6ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. What is a loss function, and why is it crucial for neural network training?\n",
    "\n",
    "#A loss function measures how far the network's predictions are from the actual target values. It quantifies the error to be minimized during training. The model uses this feedback to update weights through backpropagation. Without a loss function, the network cannot learn or improve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd139130-565a-4ebe-b6cb-ad53c0c452a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. What are some common types of loss functions?\n",
    "\n",
    "# Mean Squared Error (MSE): For regression tasks.\n",
    "\n",
    "# Binary Crossentropy: For binary classification.\n",
    "\n",
    "# Categorical Crossentropy: For multi-class classification.\n",
    "\n",
    "# Huber Loss: Combines MSE and MAE benefits.\n",
    "# Each is chosen based on the nature of the output and task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23db918-7f0b-4390-99c0-fe182a5be50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. How does a neural network learn?\n",
    "\n",
    "# A neural network learns by adjusting weights based on errors. It performs forward propagation to compute outputs, then calculates the loss. Through backpropagation, gradients are computed and used by an optimizer (like SGD or Adam) to update the weights. This process continues until the loss is minimized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c28645-cc7e-4ef2-9041-f79c4eb17838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. What is an optimizer in neural networks, and why is it necessary?\n",
    "\n",
    "#An optimizer updates the weights to minimize the loss function during training. It controls how the model converges and affects training speed and accuracy. Examples include SGD, Adam, and RMSprop. Without an optimizer, the model cannot adjust and learn effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef21343-3e64-444b-9c02-0dbfe4fcc746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Could you briefly describe some common optimizers?\n",
    "\n",
    "# SGD (Stochastic Gradient Descent): Updates weights using small batches.\n",
    "\n",
    "# Adam: Combines momentum and adaptive learning rates.\n",
    "\n",
    "# RMSprop: Uses a moving average of squared gradients.\n",
    "\n",
    "# Adagrad: Adapts learning rates per parameter.\n",
    "# Each has strengths depending on data and model structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b27d1b-9259-44e7-b5e1-b3ba5f6ccfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Can you explain forward and backward propagation in a neural network?\n",
    "\n",
    "# Forward propagation: Inputs pass through layers to compute output predictions.\n",
    "\n",
    "# Backward propagation: Computes gradients of the loss w.r.t. weights using chain rule.\n",
    "# Gradients are then used to update weights using the optimizer. This loop continues until the network learns the best weights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d8842-2179-48cf-baaf-c109fb2ef3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. What is the vanishing gradient problem in deep learning?\n",
    "\n",
    "# In deep networks, gradients can become extremely small during backpropagation. This causes early layers to learn very slowly or not at all. It’s common with activation functions like sigmoid or tanh. Solutions include ReLU activations, batch normalization, and better weight initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295ddb8-5573-432d-a4ef-793d9c5d7c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. What is the exploding gradient problem?\n",
    "\n",
    "#The exploding gradient problem occurs when gradients become too large, causing weight updates to overshoot and the model to diverge. It happens in very deep networks or with large learning rates. Solutions include gradient clipping, normalization, and using optimizers like Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe7e65-6fd7-49e6-bb9e-a507f11db15a",
   "metadata": {},
   "source": [
    "## Practical question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9581ddfd-4df7-4b68-a8fd-1bdada4202d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189d1ba-5827-46a1-a893-ea38657e4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f41239-548b-43c1-b761-e23638417fae",
   "metadata": {},
   "source": [
    "#### 16. How do you create a simple perceptron for basic binary classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff9f2a-9574-471f-9497-51613a20ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron(x, w, b):\n",
    "    z = np.dot(x, w) + b\n",
    "    return 1 if z > 0 else 0\n",
    "\n",
    "x = np.array([1, 1])\n",
    "w = np.array([0.6, -0.4])\n",
    "b = 0.2\n",
    "print(\"Perceptron Output:\", perceptron(x, w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91203f5-aca7-4502-b196-c7d2bd4cbd32",
   "metadata": {},
   "source": [
    "####  Q17. Neural Network with One Hidden Layer (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb758eb8-9108-4105-b6b5-0d51e5962f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(2,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254cfba-99bf-474b-90c0-930cf3c7dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q18: Xavier Initialization Example\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', kernel_initializer=GlorotUniform(), input_shape=(2,)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86222583-c0ca-438e-854e-96fb136bedbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q19: Different Activation Functions in Layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(2,)))\n",
    "model.add(Dense(4, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43febe-0b57-4ecf-8607-8d27f0777e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q20: Add Dropout to Network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(2,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8617e3-a325-4ed0-8818-2932b6617430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q21: Manual Forward Propagation\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "x = np.array([1.0, 2.0])\n",
    "w = np.array([0.5, -0.6])\n",
    "b = 0.1\n",
    "\n",
    "z = np.dot(x, w) + b\n",
    "a = sigmoid(z)\n",
    "print(\"Manual Forward Propagation Output:\", round(a, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e65967-910a-4bcd-86a4-0073fa76ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q22: Add Batch Normalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(2,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80be5c7-1fd4-4ac8-8454-e1f1a7a9a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q22: Add Batch Normalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(2,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ccda6-765c-4fb0-b332-add9163c50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q23: Visualize Training Process with Accuracy and Loss Curves\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "X_train = np.random.rand(100, 2)\n",
    "y_train = (X_train[:, 0] + X_train[:, 1] > 1).astype(int)\n",
    "\n",
    "X_val = np.random.rand(20, 2)\n",
    "y_val = (X_val[:, 0] + X_val[:, 1] > 1).astype(int)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(2,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, verbose=0)\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0bd4d-383f-4bba-824e-74af96f1f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q24: Use Gradient Clipping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(clipvalue=1.0)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "print(\"Gradient Clipping Applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9467fd9-bc38-479c-8ca5-65e52ced412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q25: Create Custom Loss Function\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "model.compile(optimizer='adam', loss=lambda y_true, y_pred: K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "print(\"Custom Loss Function Applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c908bb1-f31b-4b98-949c-72acb1ac92bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved as my_model.keras\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Requested the deserialization of a `lambda` object. This carries a potential risk of arbitrary code execution and thus it is disallowed by default. If you trust the source of the saved model, you can pass `safe_mode=False` to the loading function in order to allow `lambda` loading, or call `keras.config.enable_unsafe_deserialization()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Saved as my_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_model.keras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Loaded Successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_api.py:189\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    186\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    198\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:370\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    368\u001b[0m     )\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:447\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[1;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    445\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 447\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    452\u001b[0m extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:436\u001b[0m, in \u001b[0;36m_model_from_config\u001b[1;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 436\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\serialization_lib.py:734\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    732\u001b[0m     compile_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compile_config:\n\u001b[1;32m--> 734\u001b[0m         \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m         instance\u001b[38;5;241m.\u001b[39mcompiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\trainer.py:972\u001b[0m, in \u001b[0;36mTrainer.compile_from_config\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    961\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`compile()` was not called as part of model loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `compile()` method is custom. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    969\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    970\u001b[0m     )\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 972\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;66;03m# Create optimizer variables.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\serialization_lib.py:595\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m--> 595\u001b[0m         key: \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    598\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    599\u001b[0m     }\n\u001b[0;32m    601\u001b[0m class_name \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    602\u001b[0m inner_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\serialization_lib.py:643\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__lambda__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m safe_mode:\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    644\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested the deserialization of a `lambda` object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    645\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis carries a potential risk of arbitrary code execution \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    646\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus it is disallowed by default. If you trust the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    647\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource of the saved model, you can pass `safe_mode=False` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    648\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe loading function in order to allow `lambda` loading, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    649\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor call `keras.config.enable_unsafe_deserialization()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    650\u001b[0m         )\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m python_utils\u001b[38;5;241m.\u001b[39mfunc_load(inner_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__typespec__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Requested the deserialization of a `lambda` object. This carries a potential risk of arbitrary code execution and thus it is disallowed by default. If you trust the source of the saved model, you can pass `safe_mode=False` to the loading function in order to allow `lambda` loading, or call `keras.config.enable_unsafe_deserialization()`."
     ]
    }
   ],
   "source": [
    "# Q26: Save and Load Model (with H5 fallback handling)\n",
    "# Save the trained model to a file and load it back.\n",
    "# Use .keras format if h5 raises errors (recommended in TF 2.12+)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Save model in .keras format\n",
    "model.save(\"my_model.keras\")\n",
    "print(\"Model Saved as my_model.keras\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = load_model(\"my_model.keras\")\n",
    "print(\"Model Loaded Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132017f-c3e0-4882-8e9d-c02a1ef73542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
